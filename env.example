# =============================================================================
# Mira Memory Engine - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
APP_NAME=mira-memory-engine
APP_ENV=development
DEBUG=true
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# API Keys (Required)
# -----------------------------------------------------------------------------

# Deepgram - Speech-to-Text
# Get your key at: https://console.deepgram.com/
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# OpenAI - Embeddings
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic - LLM (Claude)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# -----------------------------------------------------------------------------
# Vector Database Configuration (Pinecone)
# -----------------------------------------------------------------------------

# Vector DB Provider (Pinecone only)
VECTOR_DB_PROVIDER=pinecone

# Pinecone Settings (Required)
# Get your key at: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=mira-memories

# -----------------------------------------------------------------------------
# Memory Pipeline Configuration
# -----------------------------------------------------------------------------

# Chunking Strategy:
#   - sliding_window: Fast, fixed-size chunks with overlap (default)
#   - sentence: Accumulates sentences to target size (good for conversations)
#   - paragraph: Respects paragraph boundaries (good for documents)
#   - semantic: Uses embeddings to find break points (best quality, slower)
#   - recursive: Hierarchical structure-aware splitting (good for mixed content)
CHUNK_STRATEGY=sliding_window
CHUNK_SIZE=150
CHUNK_OVERLAP=30
SEMANTIC_SIMILARITY_THRESHOLD=0.5

# Embedding
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
EMBEDDING_BATCH_SIZE=100

# Retrieval
RETRIEVAL_TOP_K=5
RETRIEVAL_SCORE_THRESHOLD=0.7

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
LLM_MODEL=claude-3-5-sonnet-20241022
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.7

# -----------------------------------------------------------------------------
# STT Configuration
# -----------------------------------------------------------------------------
STT_MODEL=nova-2
STT_LANGUAGE=en
STT_PUNCTUATE=true
STT_DIARIZE=false
STT_SMART_FORMAT=true

# -----------------------------------------------------------------------------
# Observability
# -----------------------------------------------------------------------------
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=mira-memory-engine
METRICS_ENABLED=true

# -----------------------------------------------------------------------------
# CORS Configuration
# -----------------------------------------------------------------------------
# For production, add your Vercel domain: https://your-app.vercel.app
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:3001
